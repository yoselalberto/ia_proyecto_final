{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea - Aprendizaje Supervisado\n",
    "\n",
    "En esta tarea, explorará la relación entre la complejidad del modelo y el rendimiento de la generalización, ajustando los parámetros clave de varios modelos de aprendizaje supervisado. La parte 1 de esta tarea analizará la regresión y la parte 2 analizará la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el siguiente código para crear las variables necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miembros\n",
    "Esta tarea fue hecha en equipo, por: \n",
    "* Juan Alberto Jaimes Romero\n",
    "* Francisco Torres Lastra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from   sklearn.model_selection import train_test_split\n",
    "# parameters of the execution\n",
    "np.random.seed(0)\n",
    "n = 15\n",
    "x = np.linspace(0, 10, n) + np.random.randn(n) / 5\n",
    "y = np.sin(x) + x / 6     + np.random.randn(n) / 10\n",
    "# train and test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0)\n",
    "# Puede utilizar esta función para ayudarle a visualizar el conjunto de datos\n",
    "# trazar un diagrama de dispersión de los puntos de datos en los conjuntos de entrenamiento y prueba.\n",
    "def part1_scatter():\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.scatter(x_train, y_train, label = 'training data')\n",
    "    plt.scatter(x_test,  y_test,  label = 'test data')\n",
    "    plt.legend(loc = 4)\n",
    "# viz\n",
    "part1_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1\n",
    "\n",
    "Escriba una función que se ajuste a un modelo de regresión lineal polinomial en los *datos de entrenamiento* `X_train` para los grados 1, 3, 6 y 9. (Use PolynomialFeatures en sklearn.preprocessing para crear las características polinomiales y luego ajustar un modelo de regresión lineal) Para cada modelo, encuentre 100 valores predichos en el intervalo x = 0 a 10 (por ejemplo, `np.linspace(0,10,100)`) y almacénelos en una matriz numérica. La primera fila de esta matriz debe corresponder a la salida del modelo entrenado en el grado 1, la segunda fila en el grado 3, la tercera fila en el grado 6 y la cuarta fila en el grado 9 (*Hint:* Usar `np.vstack` para agregar filas a la matriz numpy).\n",
    "\n",
    "\n",
    "La figura de arriba muestra los modelos ajustados graficados sobre los datos originales (usando `plot_one()`).\n",
    "\n",
    "*Esta función debería devolver una matriz numpy con forma `(4, 100)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta1():\n",
    "    # load dependencies\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    # reshape inputs\n",
    "    # reshape input to required form\n",
    "    x_train_reshaped = x_train.reshape(-1, 1)\n",
    "    x_test_reshaped  = x_test.reshape(-1, 1)\n",
    "    # values to predict\n",
    "    x = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    # degrees to try\n",
    "    degrees = [1, 3, 6, 9]\n",
    "    # instance empty matrix\n",
    "    resultado = np.empty(shape=(100, ))\n",
    "    # iteración\n",
    "    for i in degrees:\n",
    "        ## add polinomial features\n",
    "        poly = PolynomialFeatures(degree = i)\n",
    "        poly.fit(x_train_reshaped)\n",
    "        # transform\n",
    "        x_train_transformed = poly.transform(x_train_reshaped)\n",
    "        x_transformed       = poly.transform(x)\n",
    "        # linear regression\n",
    "        regression = LinearRegression().fit(x_train_transformed, y_train)\n",
    "        # predict\n",
    "        prediction = regression.predict(x_transformed)\n",
    "        # gather results\n",
    "        resultado = np.vstack((resultado, prediction))\n",
    "    # remove extra row\n",
    "    resultado_final = np.delete(resultado, (0), axis = 0)\n",
    "    # objeto devuelto\n",
    "    return resultado_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes usar la función plot_one() para replicar la figura del mensaje una vez que haya completado la pregunta uno\n",
    "def plot_one(degree_predictions):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.plot(x_train, y_train, 'o', label = 'training data', markersize = 10)\n",
    "    plt.plot(x_test,  y_test,  'o', label = 'test data',     markersize = 10)\n",
    "    for i, degree in enumerate([1, 3, 6, 9]):\n",
    "        plt.plot(np.linspace(0, 10, 100), degree_predictions[i], alpha = 0.8, lw = 2, label = 'degree={}'.format(degree))\n",
    "    plt.ylim(-1, 2.5)\n",
    "    plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2\n",
    "\n",
    "Escriba una función que se ajuste a un modelo de regresión lineal polinomial en los datos de entrenamiento `X_train` para los grados 0 a 9. Para cada modelo, calcule la puntuación de regresión $R^2$ (coeficiente de determinación) en los datos de entrenamiento y en los datos de la prueba y devuelve ambas matrices en una tupla.\n",
    "\n",
    "*Esta función debería devolver una tupla de matrices numpy `(r2_train, r2_test)`. Ambas matrices deben tener forma `(10,)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta2():\n",
    "    # load dependencies\n",
    "    from sklearn.linear_model  import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    # reshape inputs\n",
    "    # reshape input to required form\n",
    "    x_train_reshaped = x_train.reshape(-1, 1)\n",
    "    x_test_reshaped  = x_test.reshape(-1, 1)\n",
    "    # degrees to try\n",
    "    degrees = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    # instance empty matrix\n",
    "    r2_train = np.empty(shape=(1, ))\n",
    "    r2_test  = np.empty(shape=(1, ))\n",
    "    # iteración\n",
    "    for i in degrees:\n",
    "        ## add polinomial features\n",
    "        poly = PolynomialFeatures(degree = i)\n",
    "        poly.fit(x_train_reshaped)\n",
    "        # transform\n",
    "        x_train_transformed = poly.transform(x_train_reshaped)\n",
    "        x_test_transformed  = poly.transform(x_test_reshaped)\n",
    "        # linear regression\n",
    "        regression = LinearRegression().fit(x_train_transformed, y_train)\n",
    "        # predict in train\n",
    "        prediction_train = regression.predict(x_train_transformed)\n",
    "        # predict in test\n",
    "        prediction_test  = regression.predict(x_test_transformed)\n",
    "        ##  compute r2\n",
    "        # train\n",
    "        score_train = r2_score(y_train, prediction_train)\n",
    "        # test\n",
    "        score_test  = r2_score(y_test, prediction_test)\n",
    "        # gather results\n",
    "        r2_train = np.vstack((r2_train, score_train))\n",
    "        r2_test  = np.vstack((r2_test,  score_test))\n",
    "    # remove extra row\n",
    "    resultado = (np.delete(r2_train, (0), axis = 0), np.delete(r2_test, (0), axis = 0))\n",
    "    # objeto devuelto\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "\n",
    "Con base en las puntuaciones de $R^2$ de la pregunta 2 (niveles de grado 0 a 9), ¿Qué nivel de grado corresponde a un modelo que no se ajusta bien (underfitting)? ¿Qué grado corresponde a un modelo sobreajustado (overfitting)? ¿Qué elección de nivel de grado proporcionaría un modelo con un buen rendimiento de generalización en este conjunto de datos? Nota: puede haber varias soluciones correctas para esta pregunta.\n",
    "\n",
    "(Sugerencia: intente graficar `plt.plot` los puntajes de $R^2$ de la pregunta 2 para visualizar la relación entre el nivel de grado y $R^2$)\n",
    "\n",
    "*Esta función debería devolver una tupla con los valores de grado en este orden: `(Subajuste, Sobreajuste, Buena_Generalización)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gráfica de soporte\n",
    "(r2_score_train, r2_score_test) = respuesta2()\n",
    "#\n",
    "grados = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# plot\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.scatter(grados, r2_score_train, label = 'training data')\n",
    "plt.scatter(grados, r2_score_test,  label = 'test data')\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* el modelo sub ajustado (underfitting) es el de grado 1, su r2 es el menor en entrenamiento, y no generaliza en los datos de prueba (r2 cae en los datos de prueba)\n",
    "* el modelo con grado 9, tiene buen r2 en entrenamiento (casí perfecto), pero se convierte en el peor de todos en los datos de prueba (sobreajuste)\n",
    "* el equilibrio entre r2 en entrenamiento y prueba es el grado 6, es bueno en entrenamiento, y reporta la menor caida en los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta3():\n",
    "    respuestas = (1, 9, 6)\n",
    "    return respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4\n",
    "\n",
    "El entrenamiento de modelos en características polinomiales de alto grado puede resultar en modelos demasiado complejos que se sobreajustan, por lo que a menudo usamos versiones regularizadas del modelo para restringir la complejidad del modelo, como vimos con la regresión lineal Ridge y Lasso.\n",
    "\n",
    "Para esta pregunta, entrene dos modelos: un modelo de Regresión lineal no regularizado (parámetros predeterminados) y un modelo de Regresión de lazo regularizado (con parámetros `alpha = 0.01`,` max_iter = 10000`) en características polinómicas de grado 12. Devuelva el valor $R^2$ para los conjuntos de prueba del modelo LinearRegression y Lasso.\n",
    "\n",
    "* Esta función debería devolver una tupla `(LinearRegression_R2_score, Lasso_R2_score)` *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta4():\n",
    "    # load dependencies\n",
    "    from sklearn.linear_model  import LinearRegression\n",
    "    from sklearn.linear_model  import Lasso\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    # reshape inputs\n",
    "    # reshape input to required form\n",
    "    x_train_reshaped = x_train.reshape(-1, 1)\n",
    "    x_test_reshaped  = x_test.reshape(-1, 1)\n",
    "    # degrees to try\n",
    "    degree = 12\n",
    "    # instance empty matrix\n",
    "    # iteración\n",
    "    ## add polinomial features\n",
    "    poly = PolynomialFeatures(degree = degree)\n",
    "    poly.fit(x_train_reshaped)\n",
    "    # transform\n",
    "    x_train_transformed = poly.transform(x_train_reshaped)\n",
    "    x_test_transformed  = poly.transform(x_test_reshaped)\n",
    "    # linear regression\n",
    "    regression = LinearRegression().fit(x_train_transformed, y_train)\n",
    "    prediction_regression  = regression.predict(x_test_transformed)\n",
    "    # lasso\n",
    "    lasso = Lasso(alpha = 0.01, max_iter = 10000).fit(x_train_transformed, y_train)\n",
    "    prediction_lasso       = lasso.predict(x_test_transformed)\n",
    "    ##  compute r2\n",
    "    # regression\n",
    "    score_regression  = r2_score(y_test, prediction_regression)\n",
    "    # lasso\n",
    "    score_lasso       = r2_score(y_test, prediction_lasso)\n",
    "    # gather results\n",
    "    resultado = (score_regression, score_lasso)\n",
    "    # objeto devuelto\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos que con lasso r2 es mejor\n",
    "respuesta4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 - Clasificación\n",
    "\n",
    "Para esta sección de la tarea, trabajaremos con el [Conjunto de datos de hongos UCI] (http://archive.ics.uci.edu/ml/datasets/Mushroom?ref=datanews.io) almacenado en `mushrooms.csv` . Los datos se utilizarán para entrenar un modelo para predecir si un hongo es venenoso o no. Se proporcionan los siguientes atributos:\n",
    "\n",
    "* Información de atributos: *\n",
    "1. cap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s \n",
    "2. cap-surface: fibrous=f, grooves=g, scaly=y, smooth=s \n",
    "3. cap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y \n",
    "4. bruises?: bruises=t, no=f \n",
    "5. odor: almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s \n",
    "6. gill-attachment: attached=a, descending=d, free=f, notched=n \n",
    "7. gill-spacing: close=c, crowded=w, distant=d \n",
    "8. gill-size: broad=b, narrow=n \n",
    "9. gill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y \n",
    "10. stalk-shape: enlarging=e, tapering=t \n",
    "11. stalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=? \n",
    "12. stalk-surface-above-ring: fibrous=f, scaly=y, silky=k, smooth=s \n",
    "13. stalk-surface-below-ring: fibrous=f, scaly=y, silky=k, smooth=s \n",
    "14. stalk-color-above-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y \n",
    "15. stalk-color-below-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y \n",
    "16. veil-type: partial=p, universal=u \n",
    "17. veil-color: brown=n, orange=o, white=w, yellow=y \n",
    "18. ring-number: none=n, one=o, two=t \n",
    "19. ring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z \n",
    "20. spore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y \n",
    "21. population: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y \n",
    "22. habitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\n",
    "<br>\n",
    "\n",
    "Los datos del conjunto de datos de hongos están actualmente codificados con cadenas. Estos valores deberán codificarse en numéricos para funcionar con sklearn. Usaremos pd.get_dummies para convertir las variables categóricas en variables indicadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from   sklearn.model_selection import train_test_split\n",
    "\n",
    "# \n",
    "path = 'https://raw.githubusercontent.com/yoselalberto/ia_proyecto_final/main/data/mushrooms.csv'\n",
    "mush_df = pd.read_csv(path)\n",
    "mush_df2 = pd.get_dummies(mush_df)\n",
    "\n",
    "x_mush = mush_df2.iloc[:, 2:]\n",
    "y_mush = mush_df2.iloc[:, 1]\n",
    "\n",
    "# use las variables X_train, y_train 2 para la Pregunta 5\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_mush, y_mush, random_state = 0)\n",
    "\n",
    "# Por motivos de rendimiento en las preguntas 6 y 7, crearemos una versión más pequeña del\n",
    "# conjunto de datos de hongos completo para usar en esas preguntas. Por simplicidad, simplemente reutilizaremos\n",
    "# la división de prueba del 25% creada anteriormente como subconjunto representativo.\n",
    "#\n",
    "# Utilice las variables X_subset, y_subset para las preguntas 6 y 7.\n",
    "x_subset = x_test2\n",
    "y_subset = y_test2\n",
    "print(x_train2.shape)\n",
    "print(x_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "\n",
    "Utilizando `X_train2` y` y_train2` de la celda anterior, entrena un DecisionTreeClassifier con los parámetros predeterminados y random_state = 0. ¿Cuáles son las 5 características más importantes encontradas por el árbol de decisiones?\n",
    "\n",
    "Como recordatorio, los nombres de las características están disponibles en la propiedad `X_train2.columns`, y el orden de las características en` X_train2.columns` coincide con el orden de los valores de importancia de las características en la propiedad `feature_importances_` del clasificador.\n",
    "\n",
    "*Esta función debe devolver una lista de longitud 5 que contenga los nombres de las funciones en orden descendente de importancia.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta5():\n",
    "    # dependencies\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    # instancing, and fitting\n",
    "    arbol = DecisionTreeClassifier(random_state = 0).fit(x_train2, y_train2)\n",
    "    # 5 caracteristicas más importantes\n",
    "    caracteristicas = [caracteristica[1] for caracteristica in sorted(zip(arbol.feature_importances_, x_train2.columns), reverse = True)[:5]]\n",
    "    return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6\n",
    "\n",
    "Para esta pregunta, usaremos la función `validation_curve` en `sklearn.model_selection` para determinar los puntajes de entrenamiento y prueba para un Clasificador de vectores de soporte (`SVC`) con valores de parámetros variables. Recuerda que la función validation_curve, además de tomar un objeto clasificador no ajustado inicializado, toma un conjunto de datos como entrada y realiza sus propias divisiones internas de entrenamiento-prueba para calcular los resultados.\n",
    "\n",
    "**Debido a que la creación de una curva de validación requiere ajustar varios modelos, por razones de rendimiento, esta pregunta usará solo un subconjunto del conjunto de datos de hongos original: use las variables X_subset e y_subset como entrada para la función de la curva de validación (en lugar de X_mush e y_mush) para reducir el tiempo de cálculo.**\n",
    "\n",
    "El objeto clasificador no ajustado inicializado que usaremos es un clasificador de máquinas de vectores de soporte con kernel de base radial. Entonces, su primer paso es crear un objeto `SVC` con parámetros predeterminados (es decir,` kernel = 'rbf', C = 1`) y `random_state = 0`. Recuerde que el ancho del kernel del kernel RBF se controla mediante el parámetro `gamma`.\n",
    "\n",
    "Con este clasificador, y el conjunto de datos en X_subset, y_subset, explore el efecto de `gamma` en la precisión del clasificador usando la función` validation_curve` para encontrar los puntajes de entrenamiento y prueba para 6 valores de `gamma` desde` 0.0001` a `10 `(es decir,` np.logspace (-4,1,6) `). Recuerde que puede especificar qué métrica de puntuación desea que use validation_curve estableciendo el parámetro \"score\". En este caso, queremos utilizar la \"precisión\" como métrica de puntuación.\n",
    "\n",
    "Para cada nivel de `gamma`,` validation_curve` se ajustará a 3 modelos en diferentes subconjuntos de los datos, lo que arrojará dos matrices de 6x3 (6 niveles de gamma x 3 ajustes por nivel) de las puntuaciones para los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Encuentre la puntuación media en los tres modelos para cada nivel de \"gamma\" para ambas matrices, creando dos matrices de longitud 6 y devuelva una tupla con las dos matrices.\n",
    "\n",
    "p.ej.\n",
    "\n",
    "si uno de su conjunto de puntuaciones es\n",
    "\n",
    "    array([[ 0.5,  0.4,  0.6],\n",
    "           [ 0.7,  0.8,  0.7],\n",
    "           [ 0.9,  0.8,  0.8],\n",
    "           [ 0.8,  0.7,  0.8],\n",
    "           [ 0.7,  0.6,  0.6],\n",
    "           [ 0.4,  0.6,  0.5]])\n",
    "       \n",
    "entonces debería convertirse en\n",
    "\n",
    "    array([ 0.5,  0.73333333,  0.83333333,  0.76666667,  0.63333333, 0.5])\n",
    "\n",
    "*Esta función debería devolver una tupla de matrices numpy `(scores_entrenamiento, scores_prueba)` donde cada matriz en la tupla tiene forma `(6,)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta6():\n",
    "    # dependencias\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    from sklearn.svm import SVC\n",
    "    # values to try\n",
    "    gamma_values = np.logspace(-4, 1, 6)\n",
    "    (train_scores, test_scores) = validation_curve(SVC(random_state = 0), x_subset, y_subset, param_name = \"gamma\", param_range = gamma_values, scoring = \"precision\", cv = 3)\n",
    "    # averaging\n",
    "    train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis = 1)\n",
    "    # salida\n",
    "    result = (train_scores_mean, test_scores_mean)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 7\n",
    "\n",
    "Con base en los puntajes de la pregunta 6, ¿qué valor de gamma corresponde a un modelo que no es adecuado (y tiene la peor precisión del conjunto de entrenamiento y prueba)? ¿Qué valor de gamma corresponde a un modelo que está sobreajustado (y tiene la peor precisión del conjunto de prueba)? ¿Qué elección de gamma sería la mejor opción para un modelo con un buen rendimiento de generalización en este conjunto de datos (alta precisión tanto en el entrenamiento como en el conjunto de prueba)? Nota: puede haber varias soluciones correctas para esta pregunta.\n",
    "\n",
    "(Sugerencia: intenta graficar las puntuaciones de la pregunta 6 para visualizar la relación entre gamma y precisión).\n",
    "\n",
    "*Esta función debería devolver una tupla con los valores de grado en este orden: `(Subajuste, Sobreajuste, Buena_Generalización)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta7():\n",
    "    respuesta = (10, 10, 0.001)\n",
    "    return respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "eWYHL",
   "launcher_item_id": "BAqef",
   "part_id": "fXXRp"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
