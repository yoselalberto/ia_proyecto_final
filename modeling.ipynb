{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Modelado\n",
    "\n",
    "Ingenieria de variables básica, modelado, y predicción."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from   sklearn.impute          import SimpleImputer\n",
    "from   sklearn.preprocessing   import OneHotEncoder, StandardScaler\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.tree            import DecisionTreeClassifier\n",
    "from   sklearn.metrics         import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones\n",
    "# fe variables numericas\n",
    "def feature_engineer_numeric(dataframe, columnas_numericas):\n",
    "    df = dataframe.copy()\n",
    "    # imputación\n",
    "    imputador_numeric   = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df[columnas_numericas])\n",
    "    df_imputed = imputador_numeric.transform(df[columnas_numericas])    \n",
    "    # estandarización\n",
    "    estandarizador = StandardScaler().fit(df_imputed)\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, dataframe.drop(columns = columnas_numericas)], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# fe variables categoricas\n",
    "def feature_engineer_categoric(dataframe, columnas_categoricas):\n",
    "    df = dataframe.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = None, strategy = 'most_frequent').fit(df[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_imputed)\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambas\n",
    "def feature_engineer(dataframe, columnas_numericas, columnas_categoricas):\n",
    "    df_numeric   = feature_engineer_numeric(dataframe,    columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric(df_numeric, columnas_categoricas)\n",
    "    # salida\n",
    "    return df_categoric\n",
    "# preparación de la variable objetivo\n",
    "def ohe_objetivo(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    # \n",
    "    encoder = OneHotEncoder(handle_unknown = 'error', sparse = False).fit(df)\n",
    "    df_ohe  = encoder.transform(df)\n",
    "    # format\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres       = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # salida\n",
    "    return df_nombres, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineer for new examples, with any number of missing values\n",
    "# numeric\n",
    "def feature_engineer_numeric_new_data(dataframe_parcial, dataframe_completo, columnas_numericas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial = dataframe_parcial.copy()\n",
    "    ##  transformations\n",
    "    # imputacion\n",
    "    imputador_numeric = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df_completo[columnas_numericas])\n",
    "    df_imputed        = imputador_numeric.transform(df_parcial[columnas_numericas])\n",
    "    # estandarizado\n",
    "    estandarizador  = StandardScaler().fit(df_completo[columnas_numericas])\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, df_parcial.drop(columns = columnas_numericas)], axis = 1)\n",
    "    # \n",
    "    return df_salida\n",
    "# ingenieria de variables para las variables categoricas de los ejemplos nuevos\n",
    "def feature_engineer_categoric_new_data(dataframe_parcial, dataframe_completo, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial  = dataframe_parcial.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = '', strategy = 'most_frequent').fit(df_completo[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df_parcial[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_completo[columnas_categoricas])\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe_parcial.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambos pasos\n",
    "def feature_engineer_new_data(dataframe_parcial, dataframe_completo, columnas_numericas, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial  = dataframe_parcial.copy()\n",
    "    # magic\n",
    "    df_numeric   = feature_engineer_numeric_new_data(df_parcial,   df_completo, columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric_new_data(df_numeric, df_completo, columnas_categoricas)\n",
    "    # \n",
    "    df_salida = df_categoric\n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of new samples\n",
    "# function to fill empty values in user examples\n",
    "def complete_df(df_example):\n",
    "    # helper df\n",
    "    df_empty = pd.DataFrame([[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, '', '', '', '']], columns = columnas_predictoras)\n",
    "    # llenado\n",
    "    df_salida = pd.concat([df_empty.drop(columns = df_ejemplo_raw.columns), df_ejemplo_raw], axis = 1)\n",
    "    # \n",
    "    return df_salida\n",
    "#  prediction function\n",
    "# function to predict in human terms\n",
    "def predict_phone(ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas, modelo, encoder_objetivo, dataframe_completo):\n",
    "    # transformación para la prediccion\n",
    "    df_ejemplo_transformed = feature_engineer_new_data(ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas)\n",
    "    # predicción\n",
    "    prediccion_cruda = modelo.predict(df_ejemplo_transformed)\n",
    "    # formato más familiar\n",
    "    prediction_human = encoder_objetivo.inverse_transform(prediccion_cruda)\n",
    "    # agrupo todo en un dataframe\n",
    "    df_salida = pd.DataFrame({'producto_nombre': prediction_human[0]}).merge(dataframe_completo, on = 'producto_nombre', how = 'inner')\n",
    "    # \n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "path = 'https://raw.githubusercontent.com/yoselalberto/ia_proyecto_final/main/data/processed/celulares_procesados.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "df_inicio = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables globales\n",
    "# estas columnas serán ignoradas durante el modelado\n",
    "columnas_ignorar     = {'color', 'pantalla'}\n",
    "# variable objetivo\n",
    "columna_objetivo     = 'producto_nombre'\n",
    "# columnas categoricas\n",
    "columnas_categoricas = ['marca', 'procesador', 'sistema_operativo', 'tecnologia']\n",
    "# columnas numericas\n",
    "columnas_numericas   = ['peso', 'camara_trasera', 'camara_frontal', 'ram', 'memoria', 'precio']\n",
    "# variables predictoras\n",
    "columnas_predictoras = columnas_numericas + columnas_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino columnas, duplicados, y reordeno las columnas\n",
    "df = df_inicio.drop(columns = columnas_ignorar).drop_duplicates().reset_index(drop = True)[columnas_predictoras + [columna_objetivo]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     peso  camara_trasera  camara_frontal  ram  memoria  precio     marca  \\\n",
       "0   0.282              12              10   12      256   46799   samsung   \n",
       "1   0.272              12              12    4      512   33999     apple   \n",
       "2   0.252              12              12    4      512   31279     apple   \n",
       "3   0.302              12              10    8      256   30599   samsung   \n",
       "4   0.183              12              10    8      256   29699   samsung   \n",
       "..    ...             ...             ...  ...      ...     ...       ...   \n",
       "76  0.149              13               8    2       32    2990  motorola   \n",
       "77  0.190              13               8    1       16    2499  motorola   \n",
       "78  0.149              13               8    2       32    2990  motorola   \n",
       "79  0.176              13               8    2       32    3299    huawei   \n",
       "80  0.190              13               5    1       16    2499  motorola   \n",
       "\n",
       "   procesador sistema_operativo tecnologia       producto_nombre  \n",
       "0    qualcomm           android         5g        galaxy z fold2  \n",
       "1       apple               ios      4glte     iphone 11 pro max  \n",
       "2       apple               ios      4glte         iphone 11 pro  \n",
       "3    qualcomm           android         4g  galaxy note 20 ultra  \n",
       "4    qualcomm           android      4glte         galaxy z flip  \n",
       "..        ...               ...        ...                   ...  \n",
       "76   qualcomm           android      4glte          moto e6 plus  \n",
       "77   qualcomm           android      4glte          moto e6 play  \n",
       "78   mediatek           android      4glte          moto e6 plus  \n",
       "79   mediatek           android      4glte              honor 8a  \n",
       "80   qualcomm           android      4glte          moto e6 play  \n",
       "\n",
       "[81 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peso</th>\n      <th>camara_trasera</th>\n      <th>camara_frontal</th>\n      <th>ram</th>\n      <th>memoria</th>\n      <th>precio</th>\n      <th>marca</th>\n      <th>procesador</th>\n      <th>sistema_operativo</th>\n      <th>tecnologia</th>\n      <th>producto_nombre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.282</td>\n      <td>12</td>\n      <td>10</td>\n      <td>12</td>\n      <td>256</td>\n      <td>46799</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>5g</td>\n      <td>galaxy z fold2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.272</td>\n      <td>12</td>\n      <td>12</td>\n      <td>4</td>\n      <td>512</td>\n      <td>33999</td>\n      <td>apple</td>\n      <td>apple</td>\n      <td>ios</td>\n      <td>4glte</td>\n      <td>iphone 11 pro max</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.252</td>\n      <td>12</td>\n      <td>12</td>\n      <td>4</td>\n      <td>512</td>\n      <td>31279</td>\n      <td>apple</td>\n      <td>apple</td>\n      <td>ios</td>\n      <td>4glte</td>\n      <td>iphone 11 pro</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.302</td>\n      <td>12</td>\n      <td>10</td>\n      <td>8</td>\n      <td>256</td>\n      <td>30599</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4g</td>\n      <td>galaxy note 20 ultra</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.183</td>\n      <td>12</td>\n      <td>10</td>\n      <td>8</td>\n      <td>256</td>\n      <td>29699</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>galaxy z flip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.149</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>2990</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 plus</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.190</td>\n      <td>13</td>\n      <td>8</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2499</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 play</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.149</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>2990</td>\n      <td>motorola</td>\n      <td>mediatek</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 plus</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.176</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>3299</td>\n      <td>huawei</td>\n      <td>mediatek</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>honor 8a</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.190</td>\n      <td>13</td>\n      <td>5</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2499</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 play</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['samsung', 'apple', 'motorola', 'xiaomi', 'huawei', 'tcl', 'nokia'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df.marca.unique()"
   ]
  },
  {
   "source": [
    "## Train and test split\n",
    "Se ocuparán todos los datos para el modelado, se reportará el cross validation error. Las buenas prácticas indican usar un conjunto no visto en el entrenamiento, una excepció es cuando los datos son pocos, justo como en este caso; el cross validation error será más optimista que su desempeño real, pero es la mejor solución en esté caso."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores = df.drop(columns = columna_objetivo)\n",
    "objetivo    = df[[columna_objetivo]]"
   ]
  },
  {
   "source": [
    "## Ingeniería de variables\n",
    "\n",
    "Para llenar valores faltantes usaremos el promedio para las variables númericas, y la moda para las variables categoricas; también estandarizamos las variables númericas, restamos la media, y dividimos entre la desviación estandar.  \n",
    "Para la variable objetivo, simplemente aplicamos el one hot encoding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_transformed = feature_engineer(predictores, columnas_numericas, columnas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(objetivo_transformed, encoder_objetivo) = ohe_objetivo(objetivo)"
   ]
  },
  {
   "source": [
    "## Modelado\n",
    "\n",
    "Al final implementaremos un RandomForest, de la documentación oficial:\n",
    "\n",
    "<cite>A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</cite>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.38014705882352945 {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# creo evaluador para el grid search, utilizaré el micro f1 score\n",
    "scorer_f1  = make_scorer(f1_score, average = 'micro')\n",
    "# valores a explorar\n",
    "# parameters = {'max_depth': [2, 4, 8], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 4], 'n_estimators': [5, 10, 20]}\n",
    "parameters = {'max_depth': [2, 4, 8], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 4]}\n",
    "# ajuste y evaluacion\n",
    "# modelo = GridSearchCV(RandomForestClassifier(random_state = 59, oob_score = True, max_features = 6, class_weight = \"balanced\"), parameters, n_jobs = 6, scoring = scorer_f1, cv = 4)\n",
    "modelo = GridSearchCV(DecisionTreeClassifier(random_state = 59, max_features = 6, class_weight = \"balanced\"), parameters, n_jobs = 6, scoring = scorer_f1, cv = 5)\n",
    "# ajuste modelo\n",
    "modelo.fit(X = predictores_transformed, y = objetivo_transformed)\n",
    "# extraigo el mejor\n",
    "modelo_mejor = modelo.best_estimator_\n",
    "# ojeada\n",
    "print(modelo.best_score_, modelo.best_params_) "
   ]
  },
  {
   "source": [
    "## Preparación ejemplos nuevos\n",
    "\n",
    "Aquí transformamos la entrada del usuario, manejando pósibles valores faltantes. Hacemos la predicción, y devolvemos una tabla con la recomendación"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   peso  camara_frontal marca procesador tecnologia  precio sistema_operativo  \\\n",
       "0   NaN             NaN                                5000           android   \n",
       "\n",
       "   camara_trasera  memoria  ram  \n",
       "0              12       32    4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peso</th>\n      <th>camara_frontal</th>\n      <th>marca</th>\n      <th>procesador</th>\n      <th>tecnologia</th>\n      <th>precio</th>\n      <th>sistema_operativo</th>\n      <th>camara_trasera</th>\n      <th>memoria</th>\n      <th>ram</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>5000</td>\n      <td>android</td>\n      <td>12</td>\n      <td>32</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# example\n",
    "df_ejemplo_raw = pd.DataFrame({'precio': 5000, 'sistema_operativo': 'android', 'camara_trasera': 12, 'memoria': 32, 'ram' : 4}, index = [0])\n",
    "# completing with default values\n",
    "df_ejemplo = complete_df(df_ejemplo_raw)\n",
    "# vistazo de la entrada\n",
    "df_ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  producto_nombre    marca  color   peso      pantalla  camara_trasera  \\\n",
       "0     galaxy a20s  samsung   azul  0.185       tft-lcd              13   \n",
       "1     galaxy a20s  samsung   rojo  0.185  super amoled              13   \n",
       "2     galaxy a20s  samsung  negro  0.185  super amoled              13   \n",
       "\n",
       "   camara_frontal procesador  ram  memoria sistema_operativo  precio  \\\n",
       "0               8   qualcomm    4       32           android    4999   \n",
       "1               8   qualcomm    4       32           android    4769   \n",
       "2               8   qualcomm    4       32           android    4190   \n",
       "\n",
       "  tecnologia  \n",
       "0      4glte  \n",
       "1      4glte  \n",
       "2      4glte  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>producto_nombre</th>\n      <th>marca</th>\n      <th>color</th>\n      <th>peso</th>\n      <th>pantalla</th>\n      <th>camara_trasera</th>\n      <th>camara_frontal</th>\n      <th>procesador</th>\n      <th>ram</th>\n      <th>memoria</th>\n      <th>sistema_operativo</th>\n      <th>precio</th>\n      <th>tecnologia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>galaxy a20s</td>\n      <td>samsung</td>\n      <td>azul</td>\n      <td>0.185</td>\n      <td>tft-lcd</td>\n      <td>13</td>\n      <td>8</td>\n      <td>qualcomm</td>\n      <td>4</td>\n      <td>32</td>\n      <td>android</td>\n      <td>4999</td>\n      <td>4glte</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>galaxy a20s</td>\n      <td>samsung</td>\n      <td>rojo</td>\n      <td>0.185</td>\n      <td>super amoled</td>\n      <td>13</td>\n      <td>8</td>\n      <td>qualcomm</td>\n      <td>4</td>\n      <td>32</td>\n      <td>android</td>\n      <td>4769</td>\n      <td>4glte</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>galaxy a20s</td>\n      <td>samsung</td>\n      <td>negro</td>\n      <td>0.185</td>\n      <td>super amoled</td>\n      <td>13</td>\n      <td>8</td>\n      <td>qualcomm</td>\n      <td>4</td>\n      <td>32</td>\n      <td>android</td>\n      <td>4190</td>\n      <td>4glte</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# prediction\n",
    "predict_phone(df_ejemplo, predictores, columnas_numericas, columnas_categoricas, modelo_mejor, encoder_objetivo, df_inicio)"
   ]
  },
  {
   "source": [
    "### Ejemplo paso a paso\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n[['galaxy a20s']]\n"
     ]
    }
   ],
   "source": [
    "# prediction, paso a paso\n",
    "# def predict_phone(ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas, modelo, encoder_objetivo, dataframe_completo):\n",
    "# transformación para la prediccion\n",
    "df_ejemplo_transformed = feature_engineer_new_data(df_ejemplo, predictores, columnas_numericas, columnas_categoricas)\n",
    "# predicción\n",
    "prediccion_cruda = modelo_mejor.predict(df_ejemplo_transformed)\n",
    "print(prediccion_cruda)\n",
    "# formato más familiar\n",
    "prediction_human = encoder_objetivo.inverse_transform(prediccion_cruda)\n",
    "print(prediction_human)\n",
    "# agrupo todo en un dataframe\n",
    "# pd.DataFrame({'producto_nombre': prediction_human[0]}).merge(df_inicio, on = 'producto_nombre', how = 'inner')\n",
    "# \n",
    "#     return df_salida"
   ]
  }
 ]
}