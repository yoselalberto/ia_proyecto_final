{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Modelado\n",
    "Aquí modelaremos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from   sklearn.impute          import SimpleImputer\n",
    "from   sklearn.preprocessing   import OneHotEncoder, StandardScaler\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.metrics         import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones\n",
    "# fe variables numericas\n",
    "def feature_engineer_numeric(dataframe, columnas_numericas):\n",
    "    df = dataframe.copy()\n",
    "    # imputación\n",
    "    imputador_numeric   = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df[columnas_numericas])\n",
    "    df_imputed = imputador_numeric.transform(df[columnas_numericas])    \n",
    "    # estandarización\n",
    "    estandarizador = StandardScaler().fit(df_imputed)\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, dataframe.drop(columns = columnas_numericas)], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# fe variables categoricas\n",
    "def feature_engineer_categoric(dataframe, columnas_categoricas):\n",
    "    df = dataframe.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = None, strategy = 'most_frequent').fit(df[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_imputed)\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambas\n",
    "def feature_engineer(dataframe, columnas_numericas, columnas_categoricas):\n",
    "    df_numeric   = feature_engineer_numeric(dataframe,    columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric(df_numeric, columnas_categoricas)\n",
    "    # salida\n",
    "    return df_categoric\n",
    "# preparación de la variable objetivo\n",
    "def ohe_objetivo(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    # \n",
    "    encoder = OneHotEncoder(handle_unknown = 'error', sparse = False).fit(df)\n",
    "    df_ohe  = encoder.transform(df)\n",
    "    # format\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres       = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # salida\n",
    "    return df_nombres, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineer for new examples, with any number of missing values\n",
    "# numeric\n",
    "def feature_engineer_numeric_new_data(dataframe_parcial, dataframe_completo, columnas_numericas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial = dataframe_parcial.copy()\n",
    "    ##  transformations\n",
    "    # imputacion\n",
    "    imputador_numeric = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df_completo[columnas_numericas])\n",
    "    df_imputed        = imputador_numeric.transform(df_parcial[columnas_numericas])\n",
    "    # estandarizado\n",
    "    estandarizador  = StandardScaler().fit(df_completo[columnas_numericas])\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, df_parcial.drop(columns = columnas_numericas)], axis = 1)\n",
    "    # \n",
    "    return df_salida\n",
    "# ingenieria de variables para las variables categoricas de los ejemplos nuevos\n",
    "def feature_engineer_categoric_new_data(dataframe_parcial, dataframe_completo, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial  = dataframe_parcial.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = '', strategy = 'most_frequent').fit(df_completo[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df_parcial[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_completo[columnas_categoricas])\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe_parcial.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambos pasos\n",
    "def feature_engineer_new_data(dataframe_parcial, dataframe_completo, columnas_numericas, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial = dataframe_parcial.copy()\n",
    "    # magic\n",
    "    df_numeric   = feature_engineer_numeric_new_data(df_parcial,   df_completo, columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric_new_data(df_numeric, df_completo, columnas_categoricas)\n",
    "    # \n",
    "    df_salida = df_categoric\n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "path = 'work/data/processed/celulares_procesasdos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "df_inicio = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables globales\n",
    "# estas columnas serán ignoradas durante el modelado\n",
    "columnas_ignorar     = {'color', 'pantalla'}\n",
    "# variable objetivo\n",
    "columna_objetivo     = 'producto_nombre'\n",
    "# columnas categoricas\n",
    "columnas_categoricas = ['marca', 'procesador', 'sistema_operativo', 'tecnologia']\n",
    "# columnas numericas\n",
    "columnas_numericas   = ['peso', 'camara_trasera', 'camara_frontal', 'ram', 'memoria', 'precio']\n",
    "# variables predictoras\n",
    "columnas_predictoras = columnas_numericas + columnas_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino columnas, duplicados, y reordeno las columnas\n",
    "df = df_inicio.drop(columns = columnas_ignorar).drop_duplicates().reset_index(drop = True)[columnas_predictoras + [columna_objetivo]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     peso  camara_trasera  camara_frontal  ram  memoria  precio     marca  \\\n",
       "0   0.282              12              10   12      256   46799   samsung   \n",
       "1   0.272              12              12    4      512   33999     apple   \n",
       "2   0.252              12              12    4      512   31279     apple   \n",
       "3   0.302              12              10    8      256   30599   samsung   \n",
       "4   0.183              12              10    8      256   29699   samsung   \n",
       "..    ...             ...             ...  ...      ...     ...       ...   \n",
       "76  0.149              13               8    2       32    2990  motorola   \n",
       "77  0.190              13               8    1       16    2499  motorola   \n",
       "78  0.149              13               8    2       32    2990  motorola   \n",
       "79  0.176              13               8    2       32    3299    huawei   \n",
       "80  0.190              13               5    1       16    2499  motorola   \n",
       "\n",
       "   procesador sistema_operativo tecnologia       producto_nombre  \n",
       "0    qualcomm           android         5g        galaxy z fold2  \n",
       "1       apple               ios      4glte     iphone 11 pro max  \n",
       "2       apple               ios      4glte         iphone 11 pro  \n",
       "3    qualcomm           android         4g  galaxy note 20 ultra  \n",
       "4    qualcomm           android      4glte         galaxy z flip  \n",
       "..        ...               ...        ...                   ...  \n",
       "76   qualcomm           android      4glte          moto e6 plus  \n",
       "77   qualcomm           android      4glte          moto e6 play  \n",
       "78   mediatek           android      4glte          moto e6 plus  \n",
       "79   mediatek           android      4glte              honor 8a  \n",
       "80   qualcomm           android      4glte          moto e6 play  \n",
       "\n",
       "[81 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peso</th>\n      <th>camara_trasera</th>\n      <th>camara_frontal</th>\n      <th>ram</th>\n      <th>memoria</th>\n      <th>precio</th>\n      <th>marca</th>\n      <th>procesador</th>\n      <th>sistema_operativo</th>\n      <th>tecnologia</th>\n      <th>producto_nombre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.282</td>\n      <td>12</td>\n      <td>10</td>\n      <td>12</td>\n      <td>256</td>\n      <td>46799</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>5g</td>\n      <td>galaxy z fold2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.272</td>\n      <td>12</td>\n      <td>12</td>\n      <td>4</td>\n      <td>512</td>\n      <td>33999</td>\n      <td>apple</td>\n      <td>apple</td>\n      <td>ios</td>\n      <td>4glte</td>\n      <td>iphone 11 pro max</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.252</td>\n      <td>12</td>\n      <td>12</td>\n      <td>4</td>\n      <td>512</td>\n      <td>31279</td>\n      <td>apple</td>\n      <td>apple</td>\n      <td>ios</td>\n      <td>4glte</td>\n      <td>iphone 11 pro</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.302</td>\n      <td>12</td>\n      <td>10</td>\n      <td>8</td>\n      <td>256</td>\n      <td>30599</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4g</td>\n      <td>galaxy note 20 ultra</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.183</td>\n      <td>12</td>\n      <td>10</td>\n      <td>8</td>\n      <td>256</td>\n      <td>29699</td>\n      <td>samsung</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>galaxy z flip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.149</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>2990</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 plus</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.190</td>\n      <td>13</td>\n      <td>8</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2499</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 play</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.149</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>2990</td>\n      <td>motorola</td>\n      <td>mediatek</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 plus</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.176</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>32</td>\n      <td>3299</td>\n      <td>huawei</td>\n      <td>mediatek</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>honor 8a</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>0.190</td>\n      <td>13</td>\n      <td>5</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2499</td>\n      <td>motorola</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4glte</td>\n      <td>moto e6 play</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "## Train and test split\n",
    "Se ocuparán todos los datos para el modelado, se reportará el cross validation error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores = df.drop(columns = columna_objetivo)\n",
    "objetivo    = df[[columna_objetivo]]"
   ]
  },
  {
   "source": [
    "### Llenado de valores faltantes\n",
    "En ambos casos de usará el valor más frecuente: el promedio para las variables númericas, para las variables categoricas la moda."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_transformed = feature_engineer(predictores, columnas_numericas, columnas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(objetivo_transformed, encoder_objetivo) = ohe_objetivo(objetivo)\n",
    "# OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(objetivo).transform(objetivo)"
   ]
  },
  {
   "source": [
    "## Modelado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.16666666666666669 {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 1, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# creo evaluador para el grid search\n",
    "scorer_f1  = make_scorer(f1_score, average = 'micro')\n",
    "# valores a probar\n",
    "parameters = {'max_depth': [2, 4, 6], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4], 'n_estimators': [5, 10, 20]}\n",
    "# ajuste y evaluacion\n",
    "modelo = GridSearchCV(RandomForestClassifier(max_samples = 0.75, random_state = 59, oob_score = True, max_features = 4), parameters, n_jobs = 6, scoring = scorer_f1, cv = 4)\n",
    "# ajuste modelo\n",
    "modelo.fit(X = predictores_transformed, y = objetivo_transformed)\n",
    "# extraigo el mejor\n",
    "modelo_mejor = modelo.best_estimator_\n",
    "# ojeada\n",
    "print(modelo.best_score_, modelo.best_params_) "
   ]
  },
  {
   "source": [
    "## Preparación ejemplos nuevos\n",
    "\n",
    "Aquí transformamos la entrada del usuario."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fill empty values in the example\n",
    "def complete_df(df_example):\n",
    "    # helper df\n",
    "    df_empty = pd.DataFrame([[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, '', '', '', '']], columns = columnas_predictoras)\n",
    "    # llenado\n",
    "    df_salida = pd.concat([df_empty.drop(columns = df_ejemplo_raw.columns), df_ejemplo_raw], axis = 1)\n",
    "    # \n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "df_ejemplo_raw = pd.DataFrame({'precio': 4000, 'sistema_operativo': 'android', 'camara_frontal': 2}, index = [0])\n",
    "\n",
    "df_ejemplo = complete_df(df_ejemplo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict in human terms\n",
    "def predict_phone(df_ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas, modelo, encoder_objetivo, dataframe_completo):\n",
    "    # transformación para la prediccion\n",
    "    df_ejemplo_transformed = feature_engineer_new_data(df_ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas)\n",
    "    # predicción\n",
    "    prediccion_cruda = modelo.predict(df_ejemplo_transformed)\n",
    "    # formato más familiar\n",
    "    prediction_human = encoder_objetivo.inverse_transform(prediccion_cruda)\n",
    "    # agrupo todo en un dataframe\n",
    "    df_salida = pd.DataFrame({'producto_nombre': prediction_human[0]}).merge(dataframe_completo, on = 'producto_nombre', how = 'inner')\n",
    "    # \n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  producto_nombre  peso  camara_trasera  camara_frontal  ram  memoria  precio  \\\n",
       "0       10l t770b  0.26              16              48    6       32    6590   \n",
       "\n",
       "  marca procesador sistema_operativo tecnologia  \n",
       "0   tcl   qualcomm           android         4g  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>producto_nombre</th>\n      <th>peso</th>\n      <th>camara_trasera</th>\n      <th>camara_frontal</th>\n      <th>ram</th>\n      <th>memoria</th>\n      <th>precio</th>\n      <th>marca</th>\n      <th>procesador</th>\n      <th>sistema_operativo</th>\n      <th>tecnologia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10l t770b</td>\n      <td>0.26</td>\n      <td>16</td>\n      <td>48</td>\n      <td>6</td>\n      <td>32</td>\n      <td>6590</td>\n      <td>tcl</td>\n      <td>qualcomm</td>\n      <td>android</td>\n      <td>4g</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "predict_phone(df_ejemplo, predictores, columnas_numericas, columnas_categoricas, modelo_mejor, encoder_objetivo, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}