{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Modelado\n",
    "\n",
    "Ingenieria de variables básica, modelado, y predicción."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from   sklearn.impute          import SimpleImputer\n",
    "from   sklearn.preprocessing   import OneHotEncoder, StandardScaler\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.metrics         import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones\n",
    "# fe variables numericas\n",
    "def feature_engineer_numeric(dataframe, columnas_numericas):\n",
    "    df = dataframe.copy()\n",
    "    # imputación\n",
    "    imputador_numeric   = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df[columnas_numericas])\n",
    "    df_imputed = imputador_numeric.transform(df[columnas_numericas])    \n",
    "    # estandarización\n",
    "    estandarizador = StandardScaler().fit(df_imputed)\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, dataframe.drop(columns = columnas_numericas)], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# fe variables categoricas\n",
    "def feature_engineer_categoric(dataframe, columnas_categoricas):\n",
    "    df = dataframe.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = None, strategy = 'most_frequent').fit(df[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_imputed)\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambas\n",
    "def feature_engineer(dataframe, columnas_numericas, columnas_categoricas):\n",
    "    df_numeric   = feature_engineer_numeric(dataframe,    columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric(df_numeric, columnas_categoricas)\n",
    "    # salida\n",
    "    return df_categoric\n",
    "# preparación de la variable objetivo\n",
    "def ohe_objetivo(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    # \n",
    "    encoder = OneHotEncoder(handle_unknown = 'error', sparse = False).fit(df)\n",
    "    df_ohe  = encoder.transform(df)\n",
    "    # format\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres       = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # salida\n",
    "    return df_nombres, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineer for new examples, with any number of missing values\n",
    "# numeric\n",
    "def feature_engineer_numeric_new_data(dataframe_parcial, dataframe_completo, columnas_numericas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial = dataframe_parcial.copy()\n",
    "    ##  transformations\n",
    "    # imputacion\n",
    "    imputador_numeric = SimpleImputer(missing_values = np.nan, strategy = 'mean').fit(df_completo[columnas_numericas])\n",
    "    df_imputed        = imputador_numeric.transform(df_parcial[columnas_numericas])\n",
    "    # estandarizado\n",
    "    estandarizador  = StandardScaler().fit(df_completo[columnas_numericas])\n",
    "    df_standarizado = estandarizador.transform(df_imputed)\n",
    "    # add names\n",
    "    df_nombres = pd.DataFrame(df_standarizado, columns = columnas_numericas).reset_index(drop = True)\n",
    "    df_salida  = pd.concat([df_nombres, df_parcial.drop(columns = columnas_numericas)], axis = 1)\n",
    "    # \n",
    "    return df_salida\n",
    "# ingenieria de variables para las variables categoricas de los ejemplos nuevos\n",
    "def feature_engineer_categoric_new_data(dataframe_parcial, dataframe_completo, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial  = dataframe_parcial.copy()\n",
    "    # imputacion\n",
    "    imputador_categoric = SimpleImputer(missing_values = '', strategy = 'most_frequent').fit(df_completo[columnas_categoricas])\n",
    "    df_imputed = imputador_categoric.transform(df_parcial[columnas_categoricas])\n",
    "    # ohe\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(df_completo[columnas_categoricas])\n",
    "    df_ohe = encoder.transform(df_imputed)\n",
    "    # add names\n",
    "    columnas_nombres = encoder.get_feature_names()\n",
    "    df_nombres = pd.DataFrame(df_ohe, columns = columnas_nombres).reset_index(drop = True)\n",
    "    # gather results\n",
    "    df_salida = pd.concat([dataframe_parcial.drop(columns = columnas_categoricas), df_nombres], axis = 1)\n",
    "    #\n",
    "    return df_salida\n",
    "# junto ambos pasos\n",
    "def feature_engineer_new_data(dataframe_parcial, dataframe_completo, columnas_numericas, columnas_categoricas):\n",
    "    df_completo = dataframe_completo.copy()\n",
    "    df_parcial = dataframe_parcial.copy()\n",
    "    # magic\n",
    "    df_numeric   = feature_engineer_numeric_new_data(df_parcial,   df_completo, columnas_numericas)\n",
    "    df_categoric = feature_engineer_categoric_new_data(df_numeric, df_completo, columnas_categoricas)\n",
    "    # \n",
    "    df_salida = df_categoric\n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of new samples\n",
    "# function to fill empty values in user examples\n",
    "def complete_df(df_example):\n",
    "    # helper df\n",
    "    df_empty = pd.DataFrame([[np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, '', '', '', '']], columns = columnas_predictoras)\n",
    "    # llenado\n",
    "    df_salida = pd.concat([df_empty.drop(columns = df_ejemplo_raw.columns), df_ejemplo_raw], axis = 1)\n",
    "    # \n",
    "    return df_salida\n",
    "#  prediction function\n",
    "# function to predict in human terms\n",
    "def predict_phone(df_ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas, modelo, encoder_objetivo, dataframe_completo):\n",
    "    # transformación para la prediccion\n",
    "    df_ejemplo_transformed = feature_engineer_new_data(df_ejemplo, dataframe_entrenamiento, columnas_numericas, columnas_categoricas)\n",
    "    # predicción\n",
    "    prediccion_cruda = modelo.predict(df_ejemplo_transformed)\n",
    "    # formato más familiar\n",
    "    prediction_human = encoder_objetivo.inverse_transform(prediccion_cruda)\n",
    "    # agrupo todo en un dataframe\n",
    "    df_salida = pd.DataFrame({'producto_nombre': prediction_human[0]}).merge(dataframe_completo, on = 'producto_nombre', how = 'inner')\n",
    "    # \n",
    "    return df_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "path = 'work/data/processed/celulares_procesados.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "df_inicio = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables globales\n",
    "# estas columnas serán ignoradas durante el modelado\n",
    "columnas_ignorar     = {'color', 'pantalla'}\n",
    "# variable objetivo\n",
    "columna_objetivo     = 'producto_nombre'\n",
    "# columnas categoricas\n",
    "columnas_categoricas = ['marca', 'procesador', 'sistema_operativo', 'tecnologia']\n",
    "# columnas numericas\n",
    "columnas_numericas   = ['peso', 'camara_trasera', 'camara_frontal', 'ram', 'memoria', 'precio']\n",
    "# variables predictoras\n",
    "columnas_predictoras = columnas_numericas + columnas_categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino columnas, duplicados, y reordeno las columnas\n",
    "df = df_inicio.drop(columns = columnas_ignorar).drop_duplicates().reset_index(drop = True)[columnas_predictoras + [columna_objetivo]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "## Train and test split\n",
    "Se ocuparán todos los datos para el modelado, se reportará el cross validation error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores = df.drop(columns = columna_objetivo)\n",
    "objetivo    = df[[columna_objetivo]]"
   ]
  },
  {
   "source": [
    "### Llenado de valores faltantes\n",
    "En ambos casos de usará el valor más frecuente: el promedio para las variables númericas, para las variables categoricas la moda."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_transformed = feature_engineer(predictores, columnas_numericas, columnas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(objetivo_transformed, encoder_objetivo) = ohe_objetivo(objetivo)\n",
    "# OneHotEncoder(handle_unknown = 'ignore', sparse = False).fit(objetivo).transform(objetivo)"
   ]
  },
  {
   "source": [
    "## Modelado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo evaluador para el grid search\n",
    "scorer_f1  = make_scorer(f1_score, average = 'micro')\n",
    "# valores a probar\n",
    "parameters = {'max_depth': [2, 4, 6], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4], 'n_estimators': [5, 10, 20]}\n",
    "# ajuste y evaluacion\n",
    "modelo = GridSearchCV(RandomForestClassifier(max_samples = 0.75, random_state = 59, oob_score = True, max_features = 4), parameters, n_jobs = 6, scoring = scorer_f1, cv = 4)\n",
    "# ajuste modelo\n",
    "modelo.fit(X = predictores_transformed, y = objetivo_transformed)\n",
    "# extraigo el mejor\n",
    "modelo_mejor = modelo.best_estimator_\n",
    "# ojeada\n",
    "print(modelo.best_score_, modelo.best_params_) "
   ]
  },
  {
   "source": [
    "## Preparación ejemplos nuevos\n",
    "\n",
    "Aquí transformamos la entrada del usuario."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "df_ejemplo_raw = pd.DataFrame({'precio': 4000, 'sistema_operativo': 'android', 'camara_frontal': 2}, index = [0])\n",
    "\n",
    "df_ejemplo = complete_df(df_ejemplo_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_phone(df_ejemplo, predictores, columnas_numericas, columnas_categoricas, modelo_mejor, encoder_objetivo, df)"
   ]
  }
 ]
}